## Papers and Articles

---

### Transformer Architecture:
- [How Transformers work in deep learning and NLP: an intuitive introduction](https://theaisummer.com/transformer/)

### Optimization Techniques:
- [Transformers Optimization](https://www.scaler.com/topics/nlp/transformer-optimization/)

### Dataset Creation and Preprocessing:
- [All you need to know about text preprocessing for NLP and Machine Learning](https://www.kdnuggets.com/2019/04/text-preprocessing-nlp-machine-learning.html)

### Benchmarking and Fine-Tuning LLMs
- [Fine-Tuning LLMs: A Guide With Examples](https://www.datacamp.com/tutorial/fine-tuning-large-language-models)
- [20 LLM evaluation benchmarks and how they work](https://www.evidentlyai.com/llm-guide/llm-benchmarks)
- [RAG vs Fine-Tuning: A Comprehensive Tutorial with Practical Examples](http://datacamp.com/tutorial/rag-vs-fine-tuning)
- [Fine-Tuning LLMs: A Guide With Examples](https://www.datacamp.com/tutorial/fine-tuning-large-language-models)
- [The OpenAI API in Python](https://www.datacamp.com/cheat-sheet/the-open-ai-api-in-python)
- [Efficiently Training Transformers: A Comprehensive Guide to High-Performance NLP Models](https://www.e2enetworks.com/blog/efficiently-training-transformers-a-comprehensive-guide-to-high-performance-nlp-models)

### Multilingual NLP
- [Multilingual Language Models in Natural Language Processing (NLP) with Python](https://medium.com/%40mail4sameera/multilingual-language-models-in-natural-language-processing-nlp-with-python-9a6d1fda4adc)

### HuggingFace
- [Hugging Face 101: A Tutorial for Absolute Beginners!](https://dev.to/pavanbelagatti/hugging-face-101-a-tutorial-for-absolute-beginners-3b0l)

### Pytorch
- [PyTorch For NLP](https://medium.com/modern-nlp/get-pro-in-pytorch-for-nlp-60352b51fa1e)



## Resources
*   **Text-to-Speech Model:** [Kokoro](https://huggingface.co/hexgrad/Kokoro-82M)
*   **Speech-to-Text Model:** [Whisper](https://huggingface.co/openai/whisper-tiny.en)
*   **Voice Activity Detection Model:** [Pyannote](https://huggingface.co/pyannote/segmentation-3.0)
*   **Large Language Model Server:** [Ollama](https://ollama.ai/)
*   **Fallback Text-to-Speech Engine:** [eSpeak NG](https://github.com/espeak-ng/espeak-ng/releases/tag/1.52.0)

## Other resources for specefic need -- Speech to Speech
*   [Realtime speech to speech conversation with MiniCPM-o](https://github.com/OpenBMB/MiniCPM-o)
*   [A Comparative Guide to OpenAI and Ollama APIs](https://medium.com/@zakkyang/a-comparative-guide-to-openai-and-ollama-apis-with-cheathsheet-5aae6e515953)
*   [Building Production-Ready TTS with Kokoro-82M](https://medium.com/@simeon.emanuilov/kokoro-82m-building-production-ready-tts-with-82m-parameters-unfoldai-98e36ff286b9)
*   [Kokoro-82M: The Best TTS Model in Just 82 Million Parameters](https://medium.com/data-science-in-your-pocket/kokoro-82m-the-best-tts-model-in-just-82-million-parameters-512b4ba4f94c)
*   [StyleTTS2 Model Implementation](https://github.com/yl4579/StyleTTS2/blob/main/models.py)